<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2016/03 on Sherry&#39;s blog</title>
    <link>http://tintinsnowy.com/categories/2016/03/</link>
    <description>Recent content in 2016/03 on Sherry&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 14 Mar 2016 09:06:34 +0800</lastBuildDate>
    <atom:link href="http://tintinsnowy.com/categories/2016/03/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Spark-多节点集群配置</title>
      <link>http://tintinsnowy.com/2016/03/14/spark-%E5%A4%9A%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE</link>
      <pubDate>Mon, 14 Mar 2016 09:06:34 +0800</pubDate>
      
      <guid>http://tintinsnowy.com/2016/03/14/spark-%E5%A4%9A%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE</guid>
      <description>

&lt;h1 id=&#34;楔子:d7f0df7a88d75431aefaa0c11af54130&#34;&gt;楔子&lt;/h1&gt;

&lt;p&gt;这次完全拿到的是裸机，所以从零开始配置。其实集群和单节点差不多，见我前面的blog&lt;/p&gt;

&lt;h2 id=&#34;本机配置:d7f0df7a88d75431aefaa0c11af54130&#34;&gt;本机配置&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;Centos 5.8&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;4 cores 8G&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;节点布置-masters-slaves:d7f0df7a88d75431aefaa0c11af54130&#34;&gt;节点布置 Masters&amp;amp;Slaves&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Master   119.254.168.33&lt;/li&gt;
&lt;li&gt;Slaves1  119.254.168.34&lt;/li&gt;
&lt;li&gt;Slaves2  119.254.168.36&lt;/li&gt;
&lt;li&gt;Slaves3  119.254.168.38&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;环境配置-environment:d7f0df7a88d75431aefaa0c11af54130&#34;&gt;环境配置 Environment&lt;/h1&gt;

&lt;h3 id=&#34;java-环境:d7f0df7a88d75431aefaa0c11af54130&#34;&gt;JAVA 环境&lt;/h3&gt;

&lt;p&gt;见&lt;code&gt;Apache Spark[单节点]安装和环境配置&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;scala-环境:d7f0df7a88d75431aefaa0c11af54130&#34;&gt;SCALA 环境&lt;/h3&gt;

&lt;p&gt;见&lt;code&gt;Apache Spark[单节点]安装和环境配置&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;ssh-配置:d7f0df7a88d75431aefaa0c11af54130&#34;&gt;SSH 配置&lt;/h3&gt;

&lt;p&gt;背景：搭建Hadoop环境需要设置无密码登陆，所谓无密码登陆其实是指通过证书认证的方式登陆 ，使用一种被称为&amp;rdquo;公私钥&amp;rdquo;(RSA)认证的方式来进行ssh登录。
在linux系统中,ssh是远程登录的默认工具,因为该工具的协议使用了RSA/DSA的加密算法.该工具做linux系统的远程管理是非常安全的。&lt;/p&gt;

&lt;p&gt;所谓ssh就是ssh免密码登录服务器，其中用到了RSA加密算法。其中的细节和原理我有时间再写。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;确保安装好&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh：（ubuntu版）
$ sudo apt-get update
$ sudo apt-get install openssh-server
$ sudo /etc/init.d/ssh start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ssh(centos): 确认系统已经安装了SSH。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rpm –qa | grep openssh
rpm –qa | grep rsync


yum install ssh //安装SSH协议
yum install rsync //rsync是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;service sshd restart &amp;ndash;&amp;gt;启动服务
2. 生成并添加密钥：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    $ ssh-keygen -t rsa
    $ cat ~/.ssh/id_rsa.pub &amp;gt;&amp;gt; ~/.ssh/authorized_keys
    $ chmod 0600 ~/.ssh/authorized_keys
    service sshd restart //一般修改过都需要重启服务
如果已经生成过密钥，只需执行后两行命令。
测试ssh localhost

    $ ssh localhost
    $ exit

查看端口：是否打开

    netstat -anp |grep ssh
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;hadoop-cluster-installation:d7f0df7a88d75431aefaa0c11af54130&#34;&gt;Hadoop cluster Installation&lt;/h1&gt;

&lt;p&gt;基本和前面相同&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;修改hdfs-site.xml&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
         &amp;lt;name&amp;gt;dfs.namenode.secondary.http-address&amp;lt;/name&amp;gt;
         &amp;lt;value&amp;gt;kexinyun1:9001&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;


    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.namenode.name.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///opt/hadoop-2.6.1/dfs/name&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;


    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.datanode.data.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///opt/hadoop-2.6.1/dfs/data&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;


    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;3&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;


    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.webhdfs.enabled&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/configuration&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;mapred-site.xml&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;configuration&gt;&lt;br /&gt;
    &lt;property&gt;&lt;br /&gt;
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;&lt;br /&gt;
    &lt;value&gt;yarn&lt;/value&gt;&lt;br /&gt;
&lt;/property&gt;&lt;br /&gt;
&lt;property&gt;&lt;br /&gt;
    &lt;name&gt;mapreduce.jobtracker.http.address&lt;/name&gt;&lt;br /&gt;
    &lt;value&gt;nameNode:50030&lt;/value&gt;&lt;br /&gt;
&lt;/property&gt;&lt;br /&gt;
&lt;property&gt;&lt;br /&gt;
    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;&lt;br /&gt;
    &lt;value&gt;nameNode:10020&lt;/value&gt;&lt;br /&gt;
&lt;/property&gt;&lt;br /&gt;
&lt;property&gt;&lt;br /&gt;
    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;&lt;br /&gt;
    &lt;value&gt;nameNode:19888&lt;/value&gt;&lt;br /&gt;
&lt;/property&gt;&lt;br /&gt;
&lt;/configuration&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;yarn&lt;/p&gt;

&lt;p&gt;&lt;configuration&gt;
    &lt;!-- Site specific YARN configuration properties --&gt;
    &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
    &lt;value&gt;kexinyun1:8032&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
    &lt;value&gt;kexinyun1:8030&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
    &lt;value&gt;kexinyun1:8031&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
    &lt;value&gt;kexinyun1:8033&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
    &lt;value&gt;kexinyun1:8088&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;slaves 文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;119.254.168.38 //(slaves3)
119.254.168.36 //(slaves2)
119.254.168.34 //(slaves1)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;vi hadoop-env.sh&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export JAVA_HOME=your java home
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;vi yarn-env.sh&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export JAVA_HOME=your java home   
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;格式化（同以前）&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;启动/停止&lt;/p&gt;

&lt;p&gt;查看：jsp&lt;/p&gt;

&lt;p&gt;访问:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://ip:9001/&#34;&gt;http://ip:9001/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;spark-cluster-installation:d7f0df7a88d75431aefaa0c11af54130&#34;&gt;Spark Cluster Installation&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;基本同单节点类似&lt;/li&gt;

&lt;li&gt;&lt;p&gt;文件配置部分&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export SCALA_HOME=/opt/scala-2.11.4
export JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.101.x86_64/
export SPARK_HOME=/opt/spark
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
export SPARK_JAR=/opt/spark/lib/spark-assembly-1.6.1-hadoop2.6.0.jar
export SPARK_MASTER_IP=localhost
export SPARK_MASTER_PORT=7077
export SPARK_WORKER_CORES=1
export SPARK_WORKER_INSTANCES=1
export SPARK_WORKER_MEMORY=1g
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;启动&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$SPARK_HOME/sbin/start-all.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;problem:d7f0df7a88d75431aefaa0c11af54130&#34;&gt;problem&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.2cto.com/os/201209/155681.html&#34;&gt;http://www.2cto.com/os/201209/155681.html&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;english-version:d7f0df7a88d75431aefaa0c11af54130&#34;&gt;english version&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://pingax.com/install-hadoop2-6-0-on-ubuntu/&#34;&gt;http://pingax.com/install-hadoop2-6-0-on-ubuntu/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;reference:d7f0df7a88d75431aefaa0c11af54130&#34;&gt;Reference&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/lanxuezaipiao/p/3525554.html&#34;&gt;http://www.cnblogs.com/lanxuezaipiao/p/3525554.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://pingax.com/install-hadoop2-6-0-on-ubuntu/&#34;&gt;http://pingax.com/install-hadoop2-6-0-on-ubuntu/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html&#34;&gt;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/greensurfer/article/details/39450369&#34;&gt;http://blog.csdn.net/greensurfer/article/details/39450369&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>